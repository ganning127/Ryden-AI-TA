{"cells":[{"cell_type":"markdown","metadata":{"id":"MUUlqeLvE_tb"},"source":["# Text Summarization with Python\n","The text summarization with Python workshop is designed to be a gentle introduction to natural language processing. In this short workshop, we'll cover the basics of Python, types of text summarization, and actually build out a real-world text summarization app that you can deploy and share with friends!\n","\n","[![Workshop Cover](https://i.imgur.com/LfkpgC7.png)](https://www.canva.com/design/DAFOp9FIr4Q/_Op6f8q2fgRXSmLmufETXw/view?utm_content=DAFOp9FIr4Q&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton)\n","\n","### Workshop Resources\n","- [Slide Deck]()\n","- [Teaching Plan]()\n","- [YouTube Video Workshop]()\n","- [Student Copy of Workshop](https://colab.research.google.com/drive/1h58KbSNvtfBqaGq0Pp1KyZlTYgjbVEq_?usp=sharing)\n","\n","### Before you begin\n","1. Make a copy of this colab file by clicking `Save copy to drive`. This allows you to keep the code in your Google Drive. A new tab should be opened with the copied code file!\n","2. Start enjoying the workshop below!"]},{"cell_type":"markdown","metadata":{"id":"_mcLGQjOn4VD"},"source":["### Installing and importing dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23608,"status":"ok","timestamp":1666565322694,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"},"user_tz":240},"id":"TKtEb4FuEbWj","outputId":"310cbd8d-be24-4320-bfe2-6bf523c4b10f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gradio\n","  Downloading gradio-3.6-py3-none-any.whl (5.3 MB)\n","\u001b[K     |████████████████████████████████| 5.3 MB 27.9 MB/s \n","\u001b[?25hCollecting pydub\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from gradio) (3.8.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gradio) (3.2.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from gradio) (1.3.5)\n","Collecting fastapi\n","  Downloading fastapi-0.85.1-py3-none-any.whl (55 kB)\n","\u001b[K     |████████████████████████████████| 55 kB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from gradio) (6.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from gradio) (7.1.2)\n","Collecting ffmpy\n","  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n","Collecting python-multipart\n","  Downloading python-multipart-0.0.5.tar.gz (32 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gradio) (1.21.6)\n","Collecting orjson\n","  Downloading orjson-3.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (270 kB)\n","\u001b[K     |████████████████████████████████| 270 kB 50.6 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gradio) (2.23.0)\n","Collecting markdown-it-py[linkify,plugins]\n","  Downloading markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n","\u001b[K     |████████████████████████████████| 84 kB 2.4 MB/s \n","\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from gradio) (2.11.3)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.7/dist-packages (from gradio) (1.9.2)\n","Collecting h11<0.13,>=0.11\n","  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n","\u001b[K     |████████████████████████████████| 54 kB 2.0 MB/s \n","\u001b[?25hCollecting httpx\n","  Downloading httpx-0.23.0-py3-none-any.whl (84 kB)\n","\u001b[K     |████████████████████████████████| 84 kB 4.2 MB/s \n","\u001b[?25hCollecting uvicorn\n","  Downloading uvicorn-0.19.0-py3-none-any.whl (56 kB)\n","\u001b[K     |████████████████████████████████| 56 kB 3.3 MB/s \n","\u001b[?25hCollecting websockets\n","  Downloading websockets-10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 52.7 MB/s \n","\u001b[?25hCollecting paramiko\n","  Downloading paramiko-2.11.0-py2.py3-none-any.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 73.8 MB/s \n","\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from gradio) (2022.8.2)\n","Collecting pycryptodome\n","  Downloading pycryptodome-3.15.0-cp35-abi3-manylinux2010_x86_64.whl (2.3 MB)\n","\u001b[K     |████████████████████████████████| 2.3 MB 60.7 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (4.1.1)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (2.1.1)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (0.13.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (1.8.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (4.0.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (6.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (22.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (1.3.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (1.2.0)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp->gradio) (2.10)\n","Collecting starlette==0.20.4\n","  Downloading starlette-0.20.4-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 2.6 MB/s \n","\u001b[?25hCollecting anyio<5,>=3.4.0\n","  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n","\u001b[K     |████████████████████████████████| 80 kB 9.7 MB/s \n","\u001b[?25hCollecting sniffio>=1.1\n","  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n","Collecting rfc3986[idna2008]<2,>=1.3\n","  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx->gradio) (2022.9.24)\n","Collecting httpcore<0.16.0,>=0.15.0\n","  Downloading httpcore-0.15.0-py3-none-any.whl (68 kB)\n","\u001b[K     |████████████████████████████████| 68 kB 8.1 MB/s \n","\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->gradio) (2.0.1)\n","Collecting mdurl~=0.1\n","  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n","Collecting linkify-it-py~=1.0\n","  Downloading linkify_it_py-1.0.3-py3-none-any.whl (19 kB)\n","Collecting mdit-py-plugins\n","  Downloading mdit_py_plugins-0.3.1-py3-none-any.whl (46 kB)\n","\u001b[K     |████████████████████████████████| 46 kB 5.1 MB/s \n","\u001b[?25hCollecting uc-micro-py\n","  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (1.4.4)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->gradio) (1.15.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->gradio) (2022.4)\n","Collecting pynacl>=1.0.1\n","  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n","\u001b[K     |████████████████████████████████| 856 kB 62.2 MB/s \n","\u001b[?25hCollecting bcrypt>=3.1.3\n","  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (593 kB)\n","\u001b[K     |████████████████████████████████| 593 kB 61.0 MB/s \n","\u001b[?25hCollecting cryptography>=2.5\n","  Downloading cryptography-38.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 58.6 MB/s \n","\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.5->paramiko->gradio) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.5->paramiko->gradio) (2.21)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (1.24.3)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from uvicorn->gradio) (7.1.2)\n","Building wheels for collected packages: ffmpy, python-multipart\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4712 sha256=b389998cf293da629234e6171d38ebab0bac5b739401ed4cb38c9f1f7e1d1bbf\n","  Stored in directory: /root/.cache/pip/wheels/13/e4/6c/e8059816e86796a597c6e6b0d4c880630f51a1fcfa0befd5e6\n","  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31678 sha256=76d41c3e98dfcfb3b89206c69bb7a431671f8f48855e6143bd163ed21ebd6c06\n","  Stored in directory: /root/.cache/pip/wheels/2c/41/7c/bfd1c180534ffdcc0972f78c5758f89881602175d48a8bcd2c\n","Successfully built ffmpy python-multipart\n","Installing collected packages: sniffio, mdurl, uc-micro-py, rfc3986, markdown-it-py, h11, anyio, starlette, pynacl, mdit-py-plugins, linkify-it-py, httpcore, cryptography, bcrypt, websockets, uvicorn, python-multipart, pydub, pycryptodome, paramiko, orjson, httpx, ffmpy, fastapi, gradio\n","Successfully installed anyio-3.6.2 bcrypt-4.0.1 cryptography-38.0.1 fastapi-0.85.1 ffmpy-0.3.0 gradio-3.6 h11-0.12.0 httpcore-0.15.0 httpx-0.23.0 linkify-it-py-1.0.3 markdown-it-py-2.1.0 mdit-py-plugins-0.3.1 mdurl-0.1.2 orjson-3.8.0 paramiko-2.11.0 pycryptodome-3.15.0 pydub-0.25.1 pynacl-1.5.0 python-multipart-0.0.5 rfc3986-1.5.0 sniffio-1.3.0 starlette-0.20.4 uc-micro-py-1.0.1 uvicorn-0.19.0 websockets-10.3\n"]}],"source":["!pip install gradio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wm_q6wpyESqQ"},"outputs":[],"source":["import nltk\n","import heapq\n","import gradio as gr\n","import spacy\n","from spacy.lang.en.stop_words import STOP_WORDS\n","from string import punctuation"]},{"cell_type":"markdown","metadata":{"id":"oxZ_WOSNn7Hn"},"source":["### Finding a piece of text to summarize"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hgbqxtqKCfT5"},"outputs":[],"source":["text = \"\"\"\n","There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n","An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\n","Image collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[8] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured.\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"Gl13zXKGoQuO"},"source":["## Adding our stopwords\n","Stopwords are \"useless\" words in the English language—think words like \"a\", \"the\", or \"so\". These words don't really add much meaning to the text, so we remove them!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4RP6JEREEX85"},"outputs":[],"source":["stopwords = list(STOP_WORDS)\n","stopwords"]},{"cell_type":"markdown","metadata":{"id":"oJNUWarfoj8M"},"source":["### Loading & using our NLP model\n","Don't worry too much about understanind this for now. An NLP model is basically a tool that processes a big chunk of text!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1695,"status":"ok","timestamp":1666565384938,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"},"user_tz":240},"id":"DejMkYgNGWRS","outputId":"8c87f1f0-84db-4642-a34a-ee69f2ab030d"},"outputs":[{"data":{"text/plain":["<spacy.lang.en.English at 0x7f764ef82f90>"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["nlp = spacy.load('en_core_web_sm') # nlp is a function\n","nlp"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1666565413845,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"},"user_tz":240},"id":"DS4XvFZPChTk","outputId":"db182437-0abc-4d58-cdc5-65ac7fe7f949"},"outputs":[{"data":{"text/plain":["\n","There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n","An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\n","Image collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[8] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured."]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["doc = nlp(text) # English pipeline optimized for CPU. Components: tok2vec, tagger, parser, senter, ner, attribute_ruler, lemmatizer.\n","doc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qGSSgAf_EtjL"},"outputs":[],"source":["tokens = [token.text for token in doc]\n","tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UueijspRIQW3"},"outputs":[],"source":["cleaned = [word for word in tokens if word not in stopwords and word not in punctuation + '\\n']\n","cleaned"]},{"cell_type":"markdown","metadata":{"id":"WPwSzrBNowP1"},"source":["### Calculating word frequencies\n","We're going to create a dictionary. This dictionary will contain a key with each unique word, and a value of the number of times that word occurs in the entire piece of text.\n","\n","*Note: We're not including stopwods, as they don't mean much to the overall meaning of the text*"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1666565430348,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"},"user_tz":240},"id":"N_uqJ5jbCld1","outputId":"7847092a-c232-4a20-b0cb-2ad8aa373ca6"},"outputs":[{"data":{"text/plain":["{'There': 1,\n"," 'broadly': 1,\n"," 'types': 1,\n"," 'extractive': 1,\n"," 'summarization': 11,\n"," 'tasks': 1,\n"," 'depending': 2,\n"," 'program': 1,\n"," 'focuses': 2,\n"," 'The': 2,\n"," 'generic': 3,\n"," 'obtaining': 1,\n"," 'summary': 4,\n"," 'abstract': 2,\n"," 'collection': 3,\n"," 'documents': 2,\n"," 'sets': 1,\n"," 'images': 3,\n"," 'videos': 3,\n"," 'news': 4,\n"," 'stories': 1,\n"," 'etc': 1,\n"," 'second': 1,\n"," 'query': 4,\n"," 'relevant': 2,\n"," 'called': 2,\n"," 'based': 1,\n"," 'summarizes': 1,\n"," 'objects': 1,\n"," 'specific': 1,\n"," 'Summarization': 1,\n"," 'systems': 1,\n"," 'able': 1,\n"," 'create': 1,\n"," 'text': 1,\n"," 'summaries': 2,\n"," 'machine': 1,\n"," 'generated': 1,\n"," 'user': 1,\n"," 'needs': 1,\n"," 'An': 1,\n"," 'example': 3,\n"," 'problem': 2,\n"," 'document': 4,\n"," 'attempts': 1,\n"," 'automatically': 3,\n"," 'produce': 1,\n"," 'given': 2,\n"," 'Sometimes': 1,\n"," 'interested': 1,\n"," 'generating': 1,\n"," 'single': 1,\n"," 'source': 2,\n"," 'use': 1,\n"," 'multiple': 1,\n"," 'cluster': 1,\n"," 'articles': 3,\n"," 'topic': 2,\n"," 'This': 2,\n"," 'multi': 1,\n"," 'A': 2,\n"," 'related': 2,\n"," 'application': 2,\n"," 'summarizing': 1,\n"," 'Imagine': 1,\n"," 'system': 3,\n"," 'pulls': 1,\n"," 'web': 1,\n"," 'concisely': 1,\n"," 'represents': 1,\n"," 'latest': 1,\n"," 'Image': 1,\n"," 'automatic': 1,\n"," 'It': 1,\n"," 'consists': 1,\n"," 'selecting': 1,\n"," 'representative': 2,\n"," 'set': 2,\n"," 'larger': 1,\n"," 'images.[8': 1,\n"," 'context': 1,\n"," 'useful': 1,\n"," 'results': 1,\n"," 'image': 1,\n"," 'exploration': 1,\n"," 'Video': 1,\n"," 'domain': 1,\n"," 'creates': 1,\n"," 'trailer': 1,\n"," 'long': 1,\n"," 'video': 1,\n"," 'applications': 1,\n"," 'consumer': 1,\n"," 'personal': 1,\n"," 'want': 2,\n"," 'skip': 1,\n"," 'boring': 2,\n"," 'repetitive': 1,\n"," 'actions': 1,\n"," 'Similarly': 1,\n"," 'surveillance': 1,\n"," 'extract': 1,\n"," 'important': 1,\n"," 'suspicious': 1,\n"," 'activity': 1,\n"," 'ignoring': 1,\n"," 'redundant': 1,\n"," 'frames': 1,\n"," 'captured': 1}"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["word_frequencies = {}\n","for word in cleaned:\n","  if word not in word_frequencies.keys():\n","    word_frequencies[word] = 1\n","  else:\n","    word_frequencies[word] += 1\n","\n","word_frequencies\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":300,"status":"ok","timestamp":1666565436196,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"},"user_tz":240},"id":"x6pZqpIuCm5P","outputId":"24837d29-9006-4e1b-a9f8-56e6e951437d"},"outputs":[{"data":{"text/plain":["11"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["max_frequency = max(word_frequencies.values())\n","max_frequency"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1666565440466,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"},"user_tz":240},"id":"BrL6QW_MCn77","outputId":"59a37120-f7ac-4bea-8f21-b67bb25cea58"},"outputs":[{"data":{"text/plain":["{'There': 0.09090909090909091,\n"," 'broadly': 0.09090909090909091,\n"," 'types': 0.09090909090909091,\n"," 'extractive': 0.09090909090909091,\n"," 'summarization': 1.0,\n"," 'tasks': 0.09090909090909091,\n"," 'depending': 0.18181818181818182,\n"," 'program': 0.09090909090909091,\n"," 'focuses': 0.18181818181818182,\n"," 'The': 0.18181818181818182,\n"," 'generic': 0.2727272727272727,\n"," 'obtaining': 0.09090909090909091,\n"," 'summary': 0.36363636363636365,\n"," 'abstract': 0.18181818181818182,\n"," 'collection': 0.2727272727272727,\n"," 'documents': 0.18181818181818182,\n"," 'sets': 0.09090909090909091,\n"," 'images': 0.2727272727272727,\n"," 'videos': 0.2727272727272727,\n"," 'news': 0.36363636363636365,\n"," 'stories': 0.09090909090909091,\n"," 'etc': 0.09090909090909091,\n"," 'second': 0.09090909090909091,\n"," 'query': 0.36363636363636365,\n"," 'relevant': 0.18181818181818182,\n"," 'called': 0.18181818181818182,\n"," 'based': 0.09090909090909091,\n"," 'summarizes': 0.09090909090909091,\n"," 'objects': 0.09090909090909091,\n"," 'specific': 0.09090909090909091,\n"," 'Summarization': 0.09090909090909091,\n"," 'systems': 0.09090909090909091,\n"," 'able': 0.09090909090909091,\n"," 'create': 0.09090909090909091,\n"," 'text': 0.09090909090909091,\n"," 'summaries': 0.18181818181818182,\n"," 'machine': 0.09090909090909091,\n"," 'generated': 0.09090909090909091,\n"," 'user': 0.09090909090909091,\n"," 'needs': 0.09090909090909091,\n"," 'An': 0.09090909090909091,\n"," 'example': 0.2727272727272727,\n"," 'problem': 0.18181818181818182,\n"," 'document': 0.36363636363636365,\n"," 'attempts': 0.09090909090909091,\n"," 'automatically': 0.2727272727272727,\n"," 'produce': 0.09090909090909091,\n"," 'given': 0.18181818181818182,\n"," 'Sometimes': 0.09090909090909091,\n"," 'interested': 0.09090909090909091,\n"," 'generating': 0.09090909090909091,\n"," 'single': 0.09090909090909091,\n"," 'source': 0.18181818181818182,\n"," 'use': 0.09090909090909091,\n"," 'multiple': 0.09090909090909091,\n"," 'cluster': 0.09090909090909091,\n"," 'articles': 0.2727272727272727,\n"," 'topic': 0.18181818181818182,\n"," 'This': 0.18181818181818182,\n"," 'multi': 0.09090909090909091,\n"," 'A': 0.18181818181818182,\n"," 'related': 0.18181818181818182,\n"," 'application': 0.18181818181818182,\n"," 'summarizing': 0.09090909090909091,\n"," 'Imagine': 0.09090909090909091,\n"," 'system': 0.2727272727272727,\n"," 'pulls': 0.09090909090909091,\n"," 'web': 0.09090909090909091,\n"," 'concisely': 0.09090909090909091,\n"," 'represents': 0.09090909090909091,\n"," 'latest': 0.09090909090909091,\n"," 'Image': 0.09090909090909091,\n"," 'automatic': 0.09090909090909091,\n"," 'It': 0.09090909090909091,\n"," 'consists': 0.09090909090909091,\n"," 'selecting': 0.09090909090909091,\n"," 'representative': 0.18181818181818182,\n"," 'set': 0.18181818181818182,\n"," 'larger': 0.09090909090909091,\n"," 'images.[8': 0.09090909090909091,\n"," 'context': 0.09090909090909091,\n"," 'useful': 0.09090909090909091,\n"," 'results': 0.09090909090909091,\n"," 'image': 0.09090909090909091,\n"," 'exploration': 0.09090909090909091,\n"," 'Video': 0.09090909090909091,\n"," 'domain': 0.09090909090909091,\n"," 'creates': 0.09090909090909091,\n"," 'trailer': 0.09090909090909091,\n"," 'long': 0.09090909090909091,\n"," 'video': 0.09090909090909091,\n"," 'applications': 0.09090909090909091,\n"," 'consumer': 0.09090909090909091,\n"," 'personal': 0.09090909090909091,\n"," 'want': 0.18181818181818182,\n"," 'skip': 0.09090909090909091,\n"," 'boring': 0.18181818181818182,\n"," 'repetitive': 0.09090909090909091,\n"," 'actions': 0.09090909090909091,\n"," 'Similarly': 0.09090909090909091,\n"," 'surveillance': 0.09090909090909091,\n"," 'extract': 0.09090909090909091,\n"," 'important': 0.09090909090909091,\n"," 'suspicious': 0.09090909090909091,\n"," 'activity': 0.09090909090909091,\n"," 'ignoring': 0.09090909090909091,\n"," 'redundant': 0.09090909090909091,\n"," 'frames': 0.09090909090909091,\n"," 'captured': 0.09090909090909091}"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# normalize frequencey\n","\n","for key in word_frequencies:\n","  word_frequencies[key] /= max_frequency\n","\n","word_frequencies"]},{"cell_type":"markdown","metadata":{"id":"x3WAcycOpI2v"},"source":["### Extracting sentence tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1666565449564,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"},"user_tz":240},"id":"iZNCEX0FCpyZ","outputId":"ef108571-fb97-4861-e3ab-6171510c2f1f"},"outputs":[{"data":{"text/plain":["[,\n"," There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on.,\n"," The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).,\n"," The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.,\n"," Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.,\n"," An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.,\n"," Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic).,\n"," This problem is called multi-document summarization.,\n"," A related application is summarizing news articles.,\n"," Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.,\n"," Image collection summarization is another application example of automatic summarization.,\n"," It consists in selecting a representative set of images from a larger set of images.[8],\n"," A summary in this context is useful to show the most representative images of results in an image collection exploration system.,\n"," Video summarization is a related domain, where the system automatically creates a trailer of a long video.,\n"," This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions.,\n"," Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured.]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["sentence_tokens = [sent for sent in doc.sents]\n","sentence_tokens"]},{"cell_type":"markdown","metadata":{"id":"_VQPJiplpqP9"},"source":["### Finding sentence scores\n","We're going to score each sentence to determine how important they are to the overall piece of the text!\n","\n","***How do we do this?***\n","\n","Great question! We'll be scoring sentences using the word frequencies dictionary we created earlier. We'll loop through each word in the sentence and add up the frequencies of each word as its score."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1666565514705,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"},"user_tz":240},"id":"ONSkUNwJC5-z","outputId":"9336d910-0f60-41b8-aaee-515fc686b9ae"},"outputs":[{"data":{"text/plain":["{There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on.: 2.818181818181818,\n"," The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).: 3.9999999999999987,\n"," The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.: 3.909090909090909,\n"," Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.: 3.09090909090909,\n"," An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.: 3.9999999999999996,\n"," Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic).: 2.545454545454545,\n"," This problem is called multi-document summarization.: 1.8181818181818183,\n"," A related application is summarizing news articles.: 1.0909090909090908,\n"," Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.: 2.727272727272727,\n"," Image collection summarization is another application example of automatic summarization.: 2.909090909090909,\n"," It consists in selecting a representative set of images from a larger set of images.[8]: 1.1818181818181817,\n"," A summary in this context is useful to show the most representative images of results in an image collection exploration system.: 1.818181818181818,\n"," Video summarization is a related domain, where the system automatically creates a trailer of a long video.: 2.2727272727272725,\n"," This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions.: 1.1818181818181817,\n"," Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured.: 1.4545454545454544}"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["# using the score of each word, give sentence a score based on how often that word appered\n","\n","sentence_scores = {}\n","for sent in sentence_tokens:\n","   for word in sent:\n","     if word.text.lower() in word_frequencies:\n","       if sent not in sentence_scores.keys():\n","         sentence_scores[sent] = word_frequencies[word.text.lower()]\n","       else:\n","          sentence_scores[sent] += word_frequencies[word.text.lower()]\n","\n","sentence_scores"]},{"cell_type":"markdown","metadata":{"id":"JpClQQBCp8c7"},"source":["### Finding the sentences with the highest scores"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H8kORHxvCsMY"},"outputs":[],"source":["from heapq import nlargest\n","\n","select_length = int(len(sentence_tokens) * 0.3) # only want 0.3 percent\n","\n","summary = nlargest(select_length, sentence_scores, key=sentence_scores.get)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1666565486869,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"},"user_tz":240},"id":"vuoaL2SICzRM","outputId":"b6724611-1f22-4e75-a838-385770cabbec"},"outputs":[{"data":{"text/plain":["['An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.',\n"," 'The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).',\n"," 'The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.',\n"," 'Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\\n']"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["final_summary = [word.text for word in summary]\n","final_summary"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1666565491776,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"},"user_tz":240},"id":"RD1LF_mvC0S_","outputId":"acdd4f0e-48bf-487e-fb86-0515dc8d2ea1"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\\n'"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["final_summary = \" \".join(final_summary)\n","final_summary"]},{"cell_type":"markdown","metadata":{"id":"o8jWiaVkp-y1"},"source":["### Deployment on Gradio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J0ruitAYC7PC"},"outputs":[],"source":["# This next portion will take what you've built and deploy it on gradio\n","\n","def main(text, length):\n","    doc = nlp(text)\n","    tokens = [token.text for token in doc]\n","    cleaned = [word for word in tokens if word not in stopwords and word not in punctuation + '\\n']\n","    word_frequencies = {}\n","\n","    for word in cleaned:\n","        if word not in word_frequencies.keys():\n","            word_frequencies[word] = 1\n","        else:\n","            word_frequencies[word] += 1\n","\n","    max_frequency = max(word_frequencies.values())\n","\n","\n","    for key in word_frequencies:\n","        word_frequencies[key] /= max_frequency\n","\n","    sentence_tokens = [sent for sent in doc.sents]\n","\n","    sentence_scores = {}\n","    for sent in sentence_tokens:\n","        for word in sent:\n","            if word.text.lower() in word_frequencies:\n","                if sent not in sentence_scores.keys():\n","                    sentence_scores[sent] = word_frequencies[word.text.lower()]\n","                else:\n","                    sentence_scores[sent] += word_frequencies[word.text.lower()]\n","\n","    select_length = length\n","    summary = nlargest(select_length, sentence_scores, key=sentence_scores.get)\n","    final_summary = [word.text for word in summary]\n","    final_summary = \" \".join(final_summary)\n","    return final_summary"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":880},"executionInfo":{"elapsed":10607,"status":"ok","timestamp":1666565679950,"user":{"displayName":"Ganning Xu","userId":"02257077363614440872"},"user_tz":240},"id":"GpTSS7APGDrf","outputId":"dea19ed8-a3d6-46f8-adca-9cc53985ad4a"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/gradio/inputs.py:27: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n","  \"Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\",\n","/usr/local/lib/python3.7/dist-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n","  warnings.warn(value)\n","/usr/local/lib/python3.7/dist-packages/gradio/deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n","  warnings.warn(value)\n","/usr/local/lib/python3.7/dist-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n","  warnings.warn(value)\n","/usr/local/lib/python3.7/dist-packages/gradio/inputs.py:89: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n","  \"Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\",\n","/usr/local/lib/python3.7/dist-packages/gradio/interface.py:328: UserWarning: Currently, only the 'default' theme is supported.\n","  warnings.warn(\"Currently, only the 'default' theme is supported.\")\n"]},{"name":"stdout","output_type":"stream","text":["Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n","Running on public URL: https://267373fc9816b7b2.gradio.app\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"]},{"data":{"text/html":["<div><iframe src=\"https://267373fc9816b7b2.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["(<gradio.routes.App at 0x7f764d11f6d0>,\n"," 'http://127.0.0.1:7860/',\n"," 'https://267373fc9816b7b2.gradio.app')"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["gr.Interface(\n","  fn=main, \n","  inputs=[gr.inputs.Textbox(lines=5, placeholder=\"Enter the entire text here...\"), \n","          gr.inputs.Slider(0, 10, step=1)],\n","  outputs=[\"text\"], \n","  theme=\"huggingface\").launch(debug=False, share=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xL7xLePeIDGM"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMw2ATr28nezeZDvaSqu6PQ","collapsed_sections":["_mcLGQjOn4VD"],"provenance":[]},"kernelspec":{"display_name":"Python 3.10.7 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.7"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}
